{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd5cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c29909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473c7439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54284bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf31578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5cf954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.5, 2.3, 4. , 1.3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95483ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 2, 2, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 2,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       2, 0, 0, 0, 2, 0, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0, 1, 1, 2, 0, 1, 1,\n",
       "       0, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0,\n",
       "       2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 0, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd442d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab9b2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       2, 2, 0, 2, 0, 0, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34565ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09bcbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30, 4), dtype=float32, numpy=\n",
       "array([[5.7, 2.8, 4.1, 1.3],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.5, 2.3, 4. , 1.3]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055b1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af65b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，4个输入特征，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0891379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       "array([[ 0.08249953, -0.0683137 ,  0.19668601],\n",
       "       [-0.05480815,  0.04570521,  0.1357149 ],\n",
       "       [ 0.07750896, -0.16734955, -0.10294553],\n",
       "       [ 0.15784004, -0.13311003,  0.06045313]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a3f499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([-0.09194934, -0.12376948, -0.05381497], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ace2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39af2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf.Tensor(\n",
      "[[6.1 2.8 4.  1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.7 3.  5.  1.7]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.7 3.1 5.6 2.4]], shape=(32, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 0 0 2 2 2 1 0 0 2 0 1 0 1 0 1 2 2 1 0 0 0 0 1 1 1 0 2 0 2], shape=(32,), dtype=int64)\n",
      "-----------\n",
      "1\n",
      "tf.Tensor(\n",
      "[[5.7 2.6 3.5 1. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.6 3.  4.5 1.5]], shape=(32, 4), dtype=float32)\n",
      "tf.Tensor([1 2 2 2 0 2 2 1 0 2 2 2 2 0 0 0 0 0 0 0 0 0 1 2 2 1 1 0 0 1 0 1], shape=(32,), dtype=int64)\n",
      "-----------\n",
      "2\n",
      "tf.Tensor(\n",
      "[[5.6 2.9 3.6 1.3]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.9 3.1 5.1 2.3]], shape=(32, 4), dtype=float32)\n",
      "tf.Tensor([1 1 2 0 0 0 2 0 1 0 1 1 2 2 2 2 2 0 1 1 2 0 1 1 0 2 2 2 1 1 2 2], shape=(32,), dtype=int64)\n",
      "-----------\n",
      "3\n",
      "tf.Tensor(\n",
      "[[7.9 3.8 6.4 2. ]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.  2.2 5.  1.5]], shape=(24, 4), dtype=float32)\n",
      "tf.Tensor([2 1 2 2 0 1 1 2 2 2 1 2 1 0 2 2 2 2 2 0 1 0 1 2], shape=(24,), dtype=int64)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for step, (x_train, y_train) in enumerate(train_db):\n",
    "    print(step)\n",
    "    print(x_train)\n",
    "    print(y_train)\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a376daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2821310982108116\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.25459614023566246\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.22570249810814857\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.21028400212526321\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.19942264631390572\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.18873637914657593\n",
      "Test_acc: 0.5\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.17851299792528152\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.16922875866293907\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.16107672825455666\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.15404684841632843\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.14802726358175278\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.14287303760647774\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.1384414155036211\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.13460607640445232\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.13126072473824024\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.12831822223961353\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.12570795230567455\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.12337298691272736\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.12126746214926243\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.11935433000326157\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.11760355159640312\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.11599067784845829\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.11449568718671799\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.11310207657516003\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.11179621517658234\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.11056671850383282\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.10940408147871494\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.10830027982592583\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.10724855028092861\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.10624313354492188\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.10527909733355045\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.10435222461819649\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.10345886088907719\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.10259587690234184\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.10176052711904049\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.10095042549073696\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.10016347840428352\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.09939785115420818\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.09865193627774715\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09792428463697433\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.09721365198493004\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.09651889652013779\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.09583901986479759\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.09517311118543148\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.09452037140727043\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.0938800759613514\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.09325156547129154\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.09263425506651402\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.09202760085463524\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.09143111854791641\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.09084436669945717\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.09026693738996983\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.08969847112894058\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.08913861028850079\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.08858705125749111\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.08804351091384888\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.08750773221254349\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.0869794450700283\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.08645843155682087\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.08594448864459991\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.08543741516768932\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.08493702299892902\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.08444313518702984\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.08395559899508953\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.08347425609827042\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.0829989779740572\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.08252961374819279\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.08206604234874249\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.081608135253191\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.08115578256547451\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.08070887438952923\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.08026731759309769\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.07983099669218063\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.07939982041716576\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.07897369936108589\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.07855254597961903\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.0781362745910883\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.07772481441497803\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.07731806859374046\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.07691597566008568\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.07651845179498196\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.07612543925642967\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.07573685981333256\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.07535265013575554\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.07497274503111839\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.07459708116948605\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.07422559335827827\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.07385822664946318\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.07349491771310568\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.0731356181204319\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.07278026361018419\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.07242879923433065\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.07208118122071028\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.07173733878880739\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.07139723841100931\n",
      "Test_acc: 0.8\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, loss: 0.07106082420796156\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.07072804123163223\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.0703988391906023\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.07007317896932364\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.0697510140016675\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.06943229772150517\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.06911697331815958\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.06880500633269548\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.06849635764956474\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.06819095928221941\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.06788879912346601\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.06758982315659523\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.0672939857468009\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.06700124684721231\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.06671156734228134\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.0664249137043953\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.06614123936742544\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.06586051359772682\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.06558268424123526\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.06530773174017668\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.06503560673445463\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.06476627942174673\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.06449970323592424\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.06423586141318083\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.06397470366209745\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.06371619738638401\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.06346031557768583\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.06320702005177736\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.06295627262443304\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.06270804908126593\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.06246232055127621\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.06221904885023832\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.06197819672524929\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.061739739030599594\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.06150365062057972\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.061269890516996384\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.06103843543678522\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.060809265822172165\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.060582335107028484\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.06035762559622526\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.06013511121273041\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.05991475656628609\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.05969653092324734\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.05948041658848524\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.05926639027893543\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.05905441381037235\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.05884446855634451\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.05863653123378754\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.058430569246411324\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.05822656024247408\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.05802448373287916\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.05782431084662676\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.057626026682555676\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.05742960050702095\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.05723500158637762\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.05704221222549677\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.05685122683644295\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.0566619960591197\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.05647451803088188\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.0562887703999877\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.05610471963882446\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.055922347120940685\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.055741638876497746\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.05556256789714098\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.05538512114435434\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.055209274403750896\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.055035010911524296\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.0548623101785779\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.054691147059202194\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.05452151317149401\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.0543533880263567\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.05418673809617758\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.05402155686169863\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.05385784152895212\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.053695558570325375\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.053534683771431446\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.05337521433830261\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.05321712139993906\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.053060395643115044\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.052905027754604816\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.05275098793208599\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.05259826127439737\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.05244684685021639\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.052296712063252926\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.052147853188216686\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.052000255323946476\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.05185389053076506\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.051708764396607876\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.051564838737249374\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.051422121934592724\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.05128058698028326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.05114022362977266\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.05100102350115776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.050862948410212994\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.05072601418942213\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.050590211525559425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.05045549664646387\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.050321878865361214\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.050189340487122536\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.05005787219852209\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.04992746654897928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.04979808907955885\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.049669746309518814\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198, loss: 0.04954243544489145\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.049416122026741505\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.04929081164300442\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.0491664819419384\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.049043127335608006\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.04892073664814234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.04879930429160595\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.048678803257644176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.04855924565345049\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.0484406054019928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.048322876915335655\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.04820605181157589\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.048090120777487755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.047975064255297184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.04786088317632675\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.04774756543338299\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.047635095193982124\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.047523475252091885\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.047412686981260777\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.047302727587521076\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.047193584963679314\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.04708525072783232\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.04697771091014147\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.04687097389250994\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.04676500987261534\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.04665982723236084\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.04655539710074663\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.04645173903554678\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.04634883161634207\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.04624665342271328\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.04614521935582161\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.04604450613260269\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.04594452120363712\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.04584524128586054\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.04574667755514383\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.04564879182726145\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.04555160738527775\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.04545510280877352\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.04535927437245846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.0452641136944294\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.04516961518675089\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.045075769536197186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.044982570223510265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.044890024699270725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.04479811433702707\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.04470682516694069\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.044616163708269596\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.04452610947191715\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.04443667735904455\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.04434784967452288\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.04425961431115866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.04417197499424219\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.04408491961658001\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.043998442590236664\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.04391254670917988\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.043827214278280735\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.04374244995415211\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.043658241629600525\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.04357459396123886\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.043491484597325325\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.04340892843902111\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.04332690127193928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.04324541054666042\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.043164439499378204\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.04308400582522154\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.04300406947731972\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.04292465001344681\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.04284574929624796\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.04276734497398138\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.04268943704664707\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.04261201713234186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.04253509547561407\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.04245865158736706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.04238268360495567\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.04230719991028309\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.04223218094557524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.04215762671083212\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.04208353906869888\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.042009903118014336\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.041936720721423626\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.04186399094760418\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.041791703552007675\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.041719856671988964\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.04164844658225775\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.041577475145459175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.0415069293230772\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.041436812840402126\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.041367110796272755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.04129782598465681\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.04122895933687687\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.04116050060838461\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.041092454455792904\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.04102480225265026\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.0409575579687953\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.04089070577174425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.04082423634827137\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.0407581701874733\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.04069248493760824\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.04062718152999878\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.04056225344538689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.04049770627170801\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.04043352883309126\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.040369714610278606\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.040306275710463524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.04024319723248482\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.04018047917634249\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.0401181192137301\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.04005609964951873\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.03999444702640176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.039933123625814915\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.039872162975370884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.039811538066715\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.03975125355646014\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.03969130897894502\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.03963168477639556\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.03957239678129554\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.039513431023806334\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.03945480706170201\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.03939648950472474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.039338496048003435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.03928081598132849\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.03922344883903861\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.039166408125311136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.039109666366130114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.039053224958479404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.03899709787219763\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.03894127020612359\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.03888574196025729\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.03883050847798586\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.038775565568357706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.03872091742232442\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.038666562642902136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.03861249005421996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.03855870617553592\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.03850520867854357\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.03845198266208172\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.03839903976768255\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.03834637673571706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.03829397866502404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.03824186185374856\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.03819000767543912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.03813842451199889\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.03808710863813758\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.0380360446870327\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.03798525268211961\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.03793471725657582\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.037884446792304516\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.03783442312851548\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.03778465138748288\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.037735140416771173\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.03768586553633213\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.03763684676960111\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.03758807061240077\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.03753954125568271\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.037491252180188894\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353, loss: 0.03744320385158062\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.03739539673551917\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.03734782664105296\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.037300480995327234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.037253372836858034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.03720649890601635\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.03715985035523772\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.03711343789473176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.03706724150106311\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.03702127328142524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.036975526716560125\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.03693001065403223\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.036884700413793325\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.03683961974456906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.03679474862292409\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.036750095430761576\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.03670565178617835\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.03666142141446471\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.036617396865040064\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.036573595367372036\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.036529986653476954\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.03648658888414502\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.03644339507445693\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.036400397308170795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.03635761374607682\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.036315012257546186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.03627262357622385\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.03623042907565832\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.036188429687172174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.03614662494510412\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.03610500693321228\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.0360635737888515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.03602235112339258\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.03598130727186799\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.03594045015051961\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.03589977649971843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.03585929283872247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.03581898659467697\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.03577886801213026\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.035738937091082335\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.03569917567074299\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.03565959259867668\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.03562018508091569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.03558096382766962\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.03554191254079342\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.035503033082932234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.03546433476731181\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.035425784066319466\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.035387431271374226\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.035349234472960234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.03531121276319027\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.035273341462016106\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.03523565083742142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.03519812133163214\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.03516074921935797\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.0351235531270504\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.03508650651201606\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.0350496182218194\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.03501290176063776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.03497632686048746\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.034939910750836134\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.03490365529432893\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.03486756281927228\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.03483162447810173\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.03479582583531737\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.034760185051709414\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.03472469234839082\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.03468936076387763\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.03465416422113776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.03461912693455815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.034584224689751863\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.034549479372799397\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.034514871425926685\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.03448041249066591\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.03444609651342034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.03441192163154483\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.03437788691371679\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.03434399934485555\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.034310244023799896\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.034276635851711035\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.034243158996105194\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.03420982323586941\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.03417661692947149\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.0341435456648469\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.03411061270162463\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.03407781105488539\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.034045143984258175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.034012612886726856\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.03398020612075925\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.033947938587516546\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.033915792126208544\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.03388377791270614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.0338518894277513\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.033820136450231075\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.033788494765758514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.03375699371099472\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.033725610468536615\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.03369435342028737\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.03366321371868253\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.03363220579922199\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.03360131476074457\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.03357054106891155\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.03353989543393254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.0335093685425818\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.03347895108163357\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.033448660746216774\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.03341847890987992\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.03338842559605837\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.03335848869755864\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.033328657038509846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.03329893993213773\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.0332693406380713\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.033239858224987984\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.033210487104952335\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.03318122494965792\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.03315207874402404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.03312303684651852\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.033094109036028385\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.03306529438123107\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.0330365807749331\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.03300798311829567\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.03297948697581887\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.03295109188184142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.032922808546572924\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.03289463650435209\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.03286656178534031\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.03283859835937619\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.0328107331879437\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.03278296999633312\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.03275531530380249\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.032727756071835756\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.03270029881969094\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.03267294354736805\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.0326456930488348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.032618540339171886\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.03259148681536317\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.032564534805715084\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.03253767266869545\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.03251091903075576\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.03248425433412194\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.03245768370106816\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.03243121597915888\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.032404829282313585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.032378556206822395\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.032352367881685495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.03232627175748348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.03230027807876468\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# 训练部分\n",
    "for epoch in range(epoch):  # 数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  # batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all / 4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8774be06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABLBUlEQVR4nO3deXxU1f3/8ffMZGayh4RAFtaAILLKIiQgVWtFEXepVCsF6/KlblDqt9VSFbG/ovZbq6igtBZqrYDWDSsuUC2goFggrLJUWQIkhBCy75Pz+yPJyBjArHMnmdfz8biPzNx7587nHpC8Pffcc23GGCMAAIAgYre6AAAAAH8jAAEAgKBDAAIAAEGHAAQAAIIOAQgAAAQdAhAAAAg6BCAAABB0CEAAACDoEIAAAEDQIQABbcjixYtls9n0n//8x+pSzmj27Nmy2WynXJ599llLa5s/f74WL15cb/3+/ftls9lOuc1f1q5dqxtuuEFdunSRy+VSTEyMRo8erQULFqi4uNiyuoD2KMTqAgC0X++//75iYmJ81qWkpFhUTY358+crPj5eU6dO9VmflJSk9evXq3fv3pbU9fDDD2vOnDkaPXq0Hn30UfXu3VslJSVat26dZs+erT179uiPf/yjJbUB7REBCECrGT58uOLj460uo0HcbrdSU1Mt+e7XXntNc+bM0a233qo//elPstls3m3jx4/XL3/5S61fv75FvqukpETh4eEtciygLeMSGNAOffLJJ7r44osVFRWl8PBwjR49Wu+++67PPiUlJbrvvvuUkpKi0NBQxcXFacSIEVqyZIl3n6+//lo/+tGPlJycLLfbrYSEBF188cVKT09vVn1nutxks9k0e/Zs7/u6y2k7duzQjTfeqJiYGCUkJOinP/2p8vPzfT5bXV2tZ555Rueee67CwsLUoUMHpaamavny5ZKknj17aseOHVq9erX3klzPnj3PWFND2rLu0uTHH3+sn/3sZ4qPj1fHjh113XXX6ciRI9/ZHnPmzFFsbKzmzZvnE37qREVFady4cU1uu02bNmnixImKjY1V79699dRTT8lms+m///1vvWP86le/ksvlUk5OjnfdqlWrdPHFFys6Olrh4eEaM2aM/vWvf33neQGBjAAEtDOrV6/W97//feXn5+vFF1/UkiVLFBUVpSuvvFLLli3z7jdz5kwtWLBA9957r95//3397W9/0w9/+EMdP37cu8/ll1+ujRs36oknntDKlSu1YMECDR06VHl5eQ2qxePxqKqqyrt4PJ4mn9f111+vvn376vXXX9f999+vV155RT//+c999pk6daqmT5+u8847T8uWLdPSpUt11VVXaf/+/ZKkN998U7169dLQoUO1fv16rV+/Xm+++eZpv7OhbVnntttuk9Pp1CuvvKInnnhC//73v3XzzTef8bwyMzO1fft2jRs3rtV6Zq677jqdddZZeu211/T888/r5ptvlsvlqheiPB6PXn75ZV155ZXenruXX35Z48aNU3R0tP7617/q1VdfVVxcnC699FJCENo2A6DNWLRokZFkvvjii9Puk5qaajp37mwKCwu966qqqszAgQNN165dTXV1tTHGmIEDB5prrrnmtMfJyckxksxTTz3V6DoffvhhI6ne0qVLF2OMMfv27TOSzKJFi+p9VpJ5+OGH6x3riSee8NnvzjvvNKGhod7zWbNmjZFkZs2adcbaBgwYYC644IJ6609VU0Pbsu7P5c477/Q55hNPPGEkmczMzNPW89lnnxlJ5v777z9j3Weqs87p2u6hhx6qt+91111nunbtajwej3fdihUrjCTzzjvvGGOMKS4uNnFxcebKK6/0+azH4zFDhgwxI0eObFDNQCCiBwhoR4qLi/X5559r4sSJioyM9K53OByaPHmyDh06pN27d0uSRo4cqffee0/333+//v3vf6u0tNTnWHFxcerdu7d+//vf68knn9TmzZtVXV3dqHpWrVqlL774wrusWLGiyed21VVX+bwfPHiwysrKlJ2dLUl67733JEl33XVXk7/jZI1pyzPVKEkHDhxokZqa6vrrr6+37pZbbtGhQ4e0atUq77pFixYpMTFR48ePlyStW7dOubm5mjJlik9PXnV1tS677DJ98cUX3J2GNosABLQjJ06ckDFGSUlJ9bYlJydLkvcS17x58/SrX/1Kb731li666CLFxcXpmmuu0d69eyXVjCf517/+pUsvvVRPPPGEhg0bpk6dOunee+9VYWFhg+oZMmSIRowY4V3qAkFTdOzY0ee92+2WJG9wO3bsmBwOhxITE5v8HSdrTFs2tMZT6d69uyRp3759zar3TE51DuPHj1dSUpIWLVokqeZ8ly9frp/85CdyOBySpKNHj0qSJk6cKKfT6bM8/vjjMsYoNze31eoGWhN3gQHtSGxsrOx2uzIzM+ttqxuMWze2IyIiQo888ogeeeQRHT161NsbdOWVV2rXrl2SpB49eujFF1+UJO3Zs0evvvqqZs+erYqKCj3//PNNrjM0NFSSVF5e7rP+24GiMTp16iSPx6OsrKxT/sJvrMa0ZXMkJSVp0KBB+vDDDxt0h1ZT2u5UA6vrerLmzZunvLw8vfLKKyovL9ctt9zi3afu/J555pnT3iGXkJBwxnqBQEUPENCOREREaNSoUXrjjTd8eh2qq6v18ssvq2vXrurbt2+9zyUkJGjq1Km68cYbtXv3bpWUlNTbp2/fvvrNb36jQYMGadOmTc2qMyEhQaGhodq6davP+rfffrvJx6y7bLNgwYIz7ud2u8/YI1OnqW3ZFA8++KBOnDihe++9V8aYetuLior04YcfSmrZtrvllltUVlamJUuWaPHixUpLS1O/fv2828eMGaMOHTpo586dPj15Jy8ul6vR3wsEAnqAgDboo48+8t7ZdLLLL79cc+fO1SWXXKKLLrpI9913n1wul+bPn6/t27dryZIl3t6AUaNG6YorrtDgwYMVGxurL7/8Un/729+Ulpam8PBwbd26VXfffbd++MMfqk+fPnK5XProo4+0detW3X///c2q32az6eabb9Zf/vIX9e7dW0OGDNGGDRv0yiuvNPmYY8eO1eTJk/Xb3/5WR48e1RVXXCG3263NmzcrPDxc99xzjyRp0KBBWrp0qZYtW6ZevXopNDRUgwYNOuUxG9qWzfXDH/5QDz74oB599FHt2rVLt956q3cixM8//1wvvPCCJk2apHHjxrVo2/Xr109paWmaO3euMjIytHDhQp/tkZGReuaZZzRlyhTl5uZq4sSJ6ty5s44dO6YtW7bo2LFj3xk4gYBl7RhsAI1Rd7fR6ZZ9+/YZY4xZu3at+f73v28iIiJMWFiYSU1N9d7ZU+f+++83I0aMMLGxscbtdptevXqZn//85yYnJ8cYY8zRo0fN1KlTTb9+/UxERISJjIw0gwcPNn/84x9NVVXVGeusu/vo2LFjp90nPz/f3HbbbSYhIcFERESYK6+80uzfv/+0dzJ9+1h1bVF3zsbU3J30xz/+0QwcONC4XC4TExNj0tLSfM59//79Zty4cSYqKspIMj169DDGnP7uqoa05enuzvv444+NJPPxxx+fsb3qrF692kycONEkJSUZp9NpoqOjTVpamvn9739vCgoKWqztTrZw4UIjyYSFhZn8/PzT1jVhwgQTFxdnnE6n6dKli5kwYYJ57bXXGnReQCCyGXOK/lYAAIB2jDFAAAAg6BCAAABA0CEAAQCAoEMAAgAAQYcABAAAgg4BCAAABB0mQjyF6upqHTlyRFFRUS020RkAAGhdxhgVFhYqOTlZdvuZ+3gIQKdw5MgRdevWzeoyAABAE2RkZKhr165n3IcAdApRUVGSahowOjra4moAAEBDFBQUqFu3bt7f42dCADqFuste0dHRBCAAANqYhgxfYRA0AAAIOgQgAAAQdAhAAAAg6DAGCAAAP/N4PKqsrLS6jDbJ5XJ95y3uDUEAAgDAT4wxysrKUl5entWltFl2u10pKSlyuVzNOg4BCAAAP6kLP507d1Z4eDiT7TZS3UTFmZmZ6t69e7PajwAEAIAfeDweb/jp2LGj1eW0WZ06ddKRI0dUVVUlp9PZ5OMwCBoAAD+oG/MTHh5ucSVtW92lL4/H06zjEIAAAPAjLns1T0u1HwEIAAAEHQIQAAAIOgQgAADwnUaPHq077rjD6jJaDAHIj8qrPDqSV6ojeaVWlwIAQINVV1dr69atGjZsmNWltBgCkB9tO5Sv0Y99pB//+XOrSwEAoMF27dql4uLi0wag7du36/LLL1d0dLQSExP1i1/8QhUVFd7t1dXV+t3vfqc+ffooNDRUCQkJmjx58ndua03MA+RHTkdN3qyoqra4EgCA1YwxKq1s3q3cTRXmdDTqbqpNmzYpJCREgwcPrrdt8+bNuuCCC3Tvvfdq3rx5Onz4sG688UZ16NBBDz74oCRp7ty5WrJkiRYuXKhevXrp0KFD2rVr13dua00EID/yBiAPAQgAgl1ppUf9H/rAku/eOedShbsaHgE2bdqk/v37KzQ0tN6222+/XZMnT9Zvf/tbSdJZZ52l22+/Xf/85z+9AeiDDz7QhAkTdNFFF0mSevTooTFjxnznttbEJTA/coXUpO1KAhAAoA3ZtGnTKS9/7dq1Sxs3btQ999zjs97lcqm8vNz7/qqrrtL//d//ady4cXr++eeVm5vboG2tiR4gP6rrAarkEhgABL0wp0M751xq2Xc3lDFG6enpmjhxYr1tO3bskNPpVN++fX3W79y5U4MGDfK+v++++3TVVVfprbfe0jPPPKNf//rX2rhxo1JSUs64rTXRA+RHrpDaAOQxFlcCALCazWZTuCvEkqUx43+++uor5efnn7IHKCoqSh6Px/uYD0k6ePCg/vGPf+imm27y2bdv37765S9/qU2bNqmkpEQ7d+5s0LbWQg+QH508BsgYw3ToAICAt2nTJkmSw+HQ9u3bveudTqdGjRqluLg43X///brnnnu0f/9+3XPPPfrhD3+o8ePHS5KeeOIJJSQk6LzzzpPD4dCf//xnxcbGavTo0Wfc1toIQH5UF4AkqarayOkgAAEAAtvmzZslSampqT7rU1NTtX79er399tuaPn26XnjhBSUlJen222/X//7v/3r3Kysr0+9+9zsdPHhQkZGRGjNmjD766CPFxsaecVtrsxljuB7zLQUFBYqJiVF+fr6io6Nb7LilFR6d89D7kho/Ah8A0LaVlZVp3759SklJOeXdVGiYM7VjY35/MwbIj07u8amsIncCAGAVApAfOew21Q37YS4gAACsQwDyI5vNxmSIAAAEAAKQn7mYCwgAAMsRgPysbhwQs0EDQHDi3qPmaan2IwD5GZfAACA4OZ1OSVJJSYnFlbRtdU+ZdzgaPpv1qXAftp8xGzQABCeHw6EOHTooOztbkhQeHs6EuI1UXV2tY8eOKTw8XCEhzYswBCA/844BogcIAIJOYmKiJHlDEBrPbrere/fuzQ6PBCA/44GoABC8bDabkpKS1LlzZ5/nZ6HhXC6X7Pbmj+AhAPmZM6QmsTIGCACCl8PhaPYYFjQPg6D9zNsDxBggAAAsQwDyMydjgAAAsBwByM/qBkFXMAYIAADLEID8rG4iRMYAAQBgHQKQn3EJDAAA6xGA/MwZwm3wAABYjQDkZy7uAgMAwHIEID9z8SwwAAAsRwDys7qJEBkDBACAdQhAfsYgaAAArEcA8jPGAAEAYD0CkJ85mQgRAADLEYD8jEtgAABYjwDkZ96nwdMDBACAZQhAfuaiBwgAAMsRgPzMySBoAAAsRwDyMycTIQIAYDkCkJ+5QrgEBgCA1QhAfuZ0MBM0AABWIwD5mXcQdBVjgAAAsAoByM8YAwQAgPUsD0Dz589XSkqKQkNDNXz4cK1du/a0+77xxhu65JJL1KlTJ0VHRystLU0ffPCBzz6LFy+WzWart5SVlbX2qTSIkzFAAABYztIAtGzZMs2YMUOzZs3S5s2bNXbsWI0fP14HDx485f5r1qzRJZdcohUrVmjjxo266KKLdOWVV2rz5s0++0VHRyszM9NnCQ0N9ccpfSfGAAEAYL0QK7/8ySef1K233qrbbrtNkvTUU0/pgw8+0IIFCzR37tx6+z/11FM+73/3u9/p7bff1jvvvKOhQ4d619tsNiUmJrZq7U3l4llgAABYzrIeoIqKCm3cuFHjxo3zWT9u3DitW7euQceorq5WYWGh4uLifNYXFRWpR48e6tq1q6644op6PUTfVl5eroKCAp+ltTARIgAA1rMsAOXk5Mjj8SghIcFnfUJCgrKyshp0jD/84Q8qLi7WDTfc4F3Xr18/LV68WMuXL9eSJUsUGhqqMWPGaO/evac9zty5cxUTE+NdunXr1rSTagAGQQMAYD3LB0HbbDaf98aYeutOZcmSJZo9e7aWLVumzp07e9enpqbq5ptv1pAhQzR27Fi9+uqr6tu3r5555pnTHuuBBx5Qfn6+d8nIyGj6CX0HVwhjgAAAsJplY4Di4+PlcDjq9fZkZ2fX6xX6tmXLlunWW2/Va6+9ph/84Adn3Ndut+u88847Yw+Q2+2W2+1uePHN4L0ExhggAAAsY1kPkMvl0vDhw7Vy5Uqf9StXrtTo0aNP+7klS5Zo6tSpeuWVVzRhwoTv/B5jjNLT05WUlNTsmlvCN4/CYAwQAABWsfQusJkzZ2ry5MkaMWKE0tLStHDhQh08eFDTpk2TVHNp6vDhw3rppZck1YSfn/zkJ3r66aeVmprq7T0KCwtTTEyMJOmRRx5Ramqq+vTpo4KCAs2bN0/p6el67rnnrDnJbzl5DFBDL/cBAICWZWkAmjRpko4fP645c+YoMzNTAwcO1IoVK9SjRw9JUmZmps+cQC+88IKqqqp011136a677vKunzJlihYvXixJysvL0x133KGsrCzFxMRo6NChWrNmjUaOHOnXczudugAkSVXVxjsvEAAA8B+bMYZrMd9SUFCgmJgY5efnKzo6ukWPXVrh0TkPvS9J2jnnUoW7LM2gAAC0G435/W35XWDB5uQeHx6ICgCANQhAfuaw21Q37Kfc47G2GAAAghQByM9sNhuzQQMAYDECkAVczAUEAIClCEAW4InwAABYiwBkAZ4HBgCAtQhAFmA2aAAArEUAsoB3DBA9QAAAWIIAZAEeiAoAgLUIQBZwhtQMgmYMEAAA1iAAWYB5gAAAsBYByAJOxgABAGApApAF6gZBVzAGCAAASxCALFA3ESJjgAAAsAYByAJcAgMAwFoEIAs4Q7gNHgAAKxGALODiLjAAACxFALKAi2eBAQBgKQKQBeomQmQMEAAA1iAAWYBB0AAAWIsAZAHGAAEAYC0CkAWcTIQIAIClCEAWcDIIGgAASxGALOAdBE0PEAAAliAAWcDFIGgAACxFALIAl8AAALAWAcgCoc6aZi+rJAABAGAFApAFwlwhkqSSiiqLKwEAIDgRgCwQ4XJIkkorPBZXAgBAcCIAWSCsNgCVEIAAALAEAcgC4d5LYAQgAACsQACyQLi3B4gxQAAAWIEAZIEwJ5fAAACwEgHIAnU9QOVV1fJU80BUAAD8jQBkgboxQJJUWkkvEAAA/kYAskCo0y5bzePAGAcEAIAFCEAWsNlsCncyFxAAAFYhAFmkbjbo4nICEAAA/kYAskjdQOjSSi6BAQDgbwQgi4QzGzQAAJYhAFmEx2EAAGAdApBFwnkgKgAAliEAWSTMyfPAAACwCgHIIhFungcGAIBVCEAWYRA0AADWIQBZhEtgAABYhwBkES6BAQBgHQKQRaJCa3qACssIQAAA+BsByCLRoU5JUkFppcWVAAAQfAhAFokOqw1AZQQgAAD8jQBkkZjaAJRPDxAAAH5HALLIN5fAGAMEAIC/EYAsEh1WMwiaS2AAAPgfAcgidT1AJRUeVXqqLa4GAIDgQgCySN1t8BJ3ggEA4G8EIIuEOOyKdNddBmMcEAAA/mR5AJo/f75SUlIUGhqq4cOHa+3atafd94033tAll1yiTp06KTo6Wmlpafrggw/q7ff666+rf//+crvd6t+/v958883WPIUmi67tBaIHCAAA/7I0AC1btkwzZszQrFmztHnzZo0dO1bjx4/XwYMHT7n/mjVrdMkll2jFihXauHGjLrroIl155ZXavHmzd5/169dr0qRJmjx5srZs2aLJkyfrhhtu0Oeff+6v02ow5gICAMAaNmOMserLR40apWHDhmnBggXedeecc46uueYazZ07t0HHGDBggCZNmqSHHnpIkjRp0iQVFBTovffe8+5z2WWXKTY2VkuWLGnQMQsKChQTE6P8/HxFR0c34owa54YX1mvDvlw9e9NQXTE4udW+BwCAYNCY39+W9QBVVFRo48aNGjdunM/6cePGad26dQ06RnV1tQoLCxUXF+ddt379+nrHvPTSS894zPLychUUFPgs/sBcQAAAWMOyAJSTkyOPx6OEhASf9QkJCcrKymrQMf7whz+ouLhYN9xwg3ddVlZWo485d+5cxcTEeJdu3bo14kyajrmAAACwhuWDoG02m897Y0y9daeyZMkSzZ49W8uWLVPnzp2bdcwHHnhA+fn53iUjI6MRZ9B0dY/DYBA0AAD+FfLdu7SO+Ph4ORyOej0z2dnZ9Xpwvm3ZsmW69dZb9dprr+kHP/iBz7bExMRGH9PtdsvtdjfyDJqv7hIYzwMDAMC/LOsBcrlcGj58uFauXOmzfuXKlRo9evRpP7dkyRJNnTpVr7zyiiZMmFBve1paWr1jfvjhh2c8plW+uQuMMUAAAPiTZT1AkjRz5kxNnjxZI0aMUFpamhYuXKiDBw9q2rRpkmouTR0+fFgvvfSSpJrw85Of/ERPP/20UlNTvT09YWFhiomJkSRNnz5d3/ve9/T444/r6quv1ttvv61Vq1bpk08+seYkz4B5gAAAsIalY4AmTZqkp556SnPmzNG5556rNWvWaMWKFerRo4ckKTMz02dOoBdeeEFVVVW66667lJSU5F2mT5/u3Wf06NFaunSpFi1apMGDB2vx4sVatmyZRo0a5ffz+y4xzAMEAIAlLJ0HKFD5ax6gz74+rh8t/Ey9OkXoo19c2GrfAwBAMGgT8wCBeYAAALAKAchCzAMEAIA1CEAWqhsDVFFVrbJKj8XVAAAQPAhAFopwhcheOz8jd4IBAOA/BCAL2e02RYVyJxgAAP5GALJY3TigfAZCAwDgNwQgizEXEAAA/kcAstg3t8ITgAAA8BcCkMUIQAAA+B8ByGLfzAXEGCAAAPyFAGQx7xggeoAAAPAbApDF6i6B5ROAAADwGwKQxaK5CwwAAL8jAFnMOwaIeYAAAPAbApDFmAcIAAD/IwBZjDFAAAD4HwHIYtHcBQYAgN8RgCzmnQixrErGGIurAQAgOBCALFY3BshTbVRS4bG4GgAAggMByGKhTrucDpskxgEBAOAvBCCL2Wy2ky6DEYAAAPAHAlAA+OZxGMwFBACAPxCAAkBUbQDKK6mwuBIAAIIDASgAxIXXBSAugQEA4A8EoAAQG+GSJOXSAwQAgF8QgAJAbHhNADpRTAACAMAfCEABIK62B+gEPUAAAPgFASgA1PUA5RYzBggAAH8gAAWAuIiaQdD0AAEA4B8EoADQIZxLYAAA+BMBKAB4xwAxCBoAAL8gAAWAujFAeaWV8lTzRHgAAFobASgAdKidCNEYHogKAIA/EIACgNNhV1RoiCTGAQEA4A8EoADBOCAAAPyHABQgvpkLiAAEAEBrIwAFiFgeiAoAgN8QgAIED0QFAMB/CEABIo4HogIA4DdNCkAZGRk6dOiQ9/2GDRs0Y8YMLVy4sMUKCzbeHiACEAAAra5JAeimm27Sxx9/LEnKysrSJZdcog0bNujXv/615syZ06IFBotY7+MwGAMEAEBra1IA2r59u0aOHClJevXVVzVw4ECtW7dOr7zyihYvXtyS9QUNHogKAID/NCkAVVZWyu12S5JWrVqlq666SpLUr18/ZWZmtlx1QSSWMUAAAPhNkwLQgAED9Pzzz2vt2rVauXKlLrvsMknSkSNH1LFjxxYtMFh4J0KkBwgAgFbXpAD0+OOP64UXXtCFF16oG2+8UUOGDJEkLV++3HtpDI3TgQeiAgDgNyFN+dCFF16onJwcFRQUKDY21rv+jjvuUHh4eIsVF0xOfiBqXkmFOka6La4IAID2q0k9QKWlpSovL/eGnwMHDuipp57S7t271blz5xYtMFg4HXbvbNA5RVwGAwCgNTUpAF199dV66aWXJEl5eXkaNWqU/vCHP+iaa67RggULWrTAYNIpqqbX51hhucWVAADQvjUpAG3atEljx46VJP3jH/9QQkKCDhw4oJdeeknz5s1r0QKDSeeoUElSdmGZxZUAANC+NSkAlZSUKCoqSpL04Ycf6rrrrpPdbldqaqoOHDjQogUGE3qAAADwjyYFoLPOOktvvfWWMjIy9MEHH2jcuHGSpOzsbEVHR7dogcGkLgBlE4AAAGhVTQpADz30kO677z717NlTI0eOVFpamqSa3qChQ4e2aIHBpDM9QAAA+EWTboOfOHGizj//fGVmZnrnAJKkiy++WNdee22LFRdsvukBYgwQAACtqUkBSJISExOVmJioQ4cOyWazqUuXLkyC2EyMAQIAwD+adAmsurpac+bMUUxMjHr06KHu3burQ4cOevTRR1VdXd3SNQaNzowBAgDAL5rUAzRr1iy9+OKLeuyxxzRmzBgZY/Tpp59q9uzZKisr0//7f/+vpesMCp1qb4MvLKtSSUWVwl1N7qADAABn0KQeoL/+9a/685//rJ/97GcaPHiwhgwZojvvvFN/+tOftHjx4kYda/78+UpJSVFoaKiGDx+utWvXnnbfzMxM3XTTTTr77LNlt9s1Y8aMevssXrxYNput3lJWFvjjaqJDQxThckiSsvIDv14AANqqJgWg3Nxc9evXr976fv36KTc3t8HHWbZsmWbMmKFZs2Zp8+bNGjt2rMaPH6+DBw+ecv/y8nJ16tRJs2bN8hl8/W3R0dHKzMz0WUJDQxtcl1VsNpsSY2rqzCQAAQDQapoUgIYMGaJnn3223vpnn31WgwcPbvBxnnzySd1666267bbbdM455+ipp55St27dTvs4jZ49e+rpp5/WT37yE8XExJz2uDabzTtIu25pK5I7hEmSjuSVWlwJAADtV5MGmTzxxBOaMGGCVq1apbS0NNlsNq1bt04ZGRlasWJFg45RUVGhjRs36v777/dZP27cOK1bt64pZXkVFRWpR48e8ng8Ovfcc/Xoo4+2mfmJkmp7gLgEBgBA62lSD9AFF1ygPXv26Nprr1VeXp5yc3N13XXXaceOHVq0aFGDjpGTkyOPx6OEhASf9QkJCcrKympKWZJqLsMtXrxYy5cv15IlSxQaGqoxY8Zo7969p/1MeXm5CgoKfBarJMbU9gARgAAAaDVNvs0oOTm53t1eW7Zs0V//+lf95S9/afBxbDabz3tjTL11jZGamqrU1FTv+zFjxmjYsGF65plnTvug1rlz5+qRRx5p8ne2pGRvDxCXwAAAaC1N6gFqCfHx8XI4HPV6e7Kzs+v1CjWH3W7Xeeedd8YeoAceeED5+fneJSMjo8W+v7EYBA0AQOuzLAC5XC4NHz5cK1eu9Fm/cuVKjR49usW+xxij9PR0JSUlnXYft9ut6Ohon8UqXWoHQR8+USpjjGV1AADQnlk6097MmTM1efJkjRgxQmlpaVq4cKEOHjyoadOmSarpmTl8+LBeeukl72fS09Ml1Qx0PnbsmNLT0+VyudS/f39J0iOPPKLU1FT16dNHBQUFmjdvntLT0/Xcc8/5/fyaomtsuCSpsLxK+aWV6hDusrgiAADan0YFoOuuu+6M2/Py8hr15ZMmTdLx48c1Z84cZWZmauDAgVqxYoV69OghqWbiw2/PCXTy3VwbN27UK6+8oh49emj//v3eGu644w5lZWUpJiZGQ4cO1Zo1a9rMc8rCXA7FR7qVU1SujNxSAhAAAK3AZhpxneWWW25p0H4NvRMsUBUUFCgmJkb5+fmWXA67dv6n2nwwT/N/PEyXDzr9pTsAAPCNxvz+blQPUFsPNm1F97hwbT6Yp4zcEqtLAQCgXbJsEDROr1vtOKCDBCAAAFoFASgAdY+rCUAZJ5gLCACA1kAACkDdagPQgePFFlcCAED7RAAKQL06RUiSMnJLVF7lsbgaAADaHwJQAOoc5VaEy6FqIx08zjggAABaGgEoANlsNvXqFClJ+uoYl8EAAGhpBKAAVXcZbF8OAQgAgJZGAApQveJreoC+PlZkcSUAALQ/BKAA1btzTQ/Q3mwCEAAALY0AFKDOToiSJO05Wqjqap4KDwBASyIABaie8RFyOewqqfDoEBMiAgDQoghAAcrpsKt355pxQLuyCiyuBgCA9oUAFMD6JdZcBtudVWhxJQAAtC8EoABWF4B2ZtIDBABASyIABbDBXTtIktIz8iytAwCA9oYAFMAGd42R3SZl5pfpaEGZ1eUAANBuEIACWIQ7RH1rb4enFwgAgJZDAApwQ7gMBgBAiyMABbhzu3eQJG0hAAEA0GIIQAHu3G4dJElbD+XLw4zQAAC0CAJQgOvTOVJhToeKyqv0FQ9GBQCgRRCAAlyIw65BXWMkSZsPnrC4GgAA2gcCUBswKiVOkvTpf49bXAkAAO0DAagNGNunkyTpk//m8GR4AABaAAGoDRjavYMiXA7lFlfwWAwAAFoAAagNcDrsSuvdUZK0dm+OxdUAAND2EYDaiPPPipckrd17zOJKAABo+whAbcTYvjXjgP6z/4RKKzwWVwMAQNtGAGojesVHqEuHMFV4qvXJf7kMBgBAcxCA2gibzaZLByRKklZsy7S4GgAA2jYCUBsyYXBNAFq586jKKrkMBgBAUxGA2pCh3WKVFBOqovIq7gYDAKAZCEBtiN1u0+WDkiRJ7249YnE1AAC0XQSgNqYuAK36Mpu7wQAAaCICUBsztFsHdY8LV1F5lf5JLxAAAE1CAGpj7HabfjSymyRpyYaDFlcDAEDbRABqgyYO76oQu02bDuZpVxbPBgMAoLEIQG1Q56hQjRuQIEl65XN6gQAAaCwCUBt148jukqTXNx5SfkmlxdUAANC2EIDaqPPPile/xCgVV3j08ucHrC4HAIA2hQDURtlsNv3PBb0kSYs+3cfM0AAANAIBqA27YnCyunQIU05Rhf6x8ZDV5QAA0GYQgNowp8Ou28amSJKe+/i/9AIBANBABKA27saR3ZUUE6rM/DK9/BljgQAAaAgCUBsX6nTo5z/oK6mmF6igjDvCAAD4LgSgduC6YV3Uu1OETpRUav7HX1ldDgAAAY8A1A6EOOy6f/w5kqQXP/laXx8rsrgiAAACGwGonfjBOZ114dmdVOkxeuSdnTLGWF0SAAABiwDUTthsNj185QC5HHat3nNM727LtLokAAACFgGoHUmJj9C0C3tLkh56e4dyisotrggAgMBEAGpn7r7oLPVLjFJucYUeenu71eUAABCQCEDtjCvErv/74RCF2G1asS1L/9x6xOqSAAAIOASgdmhglxjdedFZkqTfvLVdR/JKLa4IAIDAQgBqp+6+6CwN7BKtvJJK3bNksyo91VaXBABAwCAAtVOuELueu2mYotwh2njghP7w4R6rSwIAIGAQgNqxHh0j9PjEwZKk51d/pY92HbW4IgAAAoPlAWj+/PlKSUlRaGiohg8frrVr155238zMTN100006++yzZbfbNWPGjFPu9/rrr6t///5yu93q37+/3nzzzVaqPvBdPihJU9J6SJKmL0nXf7OZJRoAAEsD0LJlyzRjxgzNmjVLmzdv1tixYzV+/HgdPHjwlPuXl5erU6dOmjVrloYMGXLKfdavX69JkyZp8uTJ2rJliyZPnqwbbrhBn3/+eWueSkD79YRzdF7PWBWWV+m2v36hvJIKq0sCAMBSNmPhMxNGjRqlYcOGacGCBd5155xzjq655hrNnTv3jJ+98MILde655+qpp57yWT9p0iQVFBTovffe86677LLLFBsbqyVLljSoroKCAsXExCg/P1/R0dENP6EAllNUrquf/VSH80o1undH/fWnI+V0WN4BCABAi2nM72/LfgNWVFRo48aNGjdunM/6cePGad26dU0+7vr16+sd89JLLz3jMcvLy1VQUOCztDfxkW79ecoIhbscWvfVcT3wxjaeFwYACFqWBaCcnBx5PB4lJCT4rE9ISFBWVlaTj5uVldXoY86dO1cxMTHepVu3bk3+/kB2TlK0nrlxqBx2m/6x8ZAee3+X1SUBAGAJy6+B2Gw2n/fGmHrrWvuYDzzwgPLz871LRkZGs74/kF18ToLmXjdIkvTC6q/157VfW1wRAAD+F2LVF8fHx8vhcNTrmcnOzq7Xg9MYiYmJjT6m2+2W2+1u8ne2NTeM6KbjRRV6/P1d+u27XyouwqXrhnW1uiwAAPzGsh4gl8ul4cOHa+XKlT7rV65cqdGjRzf5uGlpafWO+eGHHzbrmO3RtAt66dbzUyRJ//uPrTwzDAAQVCzrAZKkmTNnavLkyRoxYoTS0tK0cOFCHTx4UNOmTZNUc2nq8OHDeumll7yfSU9PlyQVFRXp2LFjSk9Pl8vlUv/+/SVJ06dP1/e+9z09/vjjuvrqq/X2229r1apV+uSTT/x+foHMZrNp1uXnqKC0Uq9tPKTpS9MlSVcMTra2MAAA/MDSADRp0iQdP35cc+bMUWZmpgYOHKgVK1aoR4+aifsyMzPrzQk0dOhQ7+uNGzfqlVdeUY8ePbR//35J0ujRo7V06VL95je/0YMPPqjevXtr2bJlGjVqlN/Oq62w22167PrBMpL+QQgCAAQRS+cBClTtcR6gM/FUG/3yH1v1+qZDcthtevKGIbr63C5WlwUAQKO0iXmAEDgcdpuemDhY1w/rKk+10Yxl6frb+v1WlwUAQKshAEHSNyFocmoPGSM9+PYOPb1qL5MlAgDaJQIQvBx2m+ZcPUD3XtxHkvTHVXv0yDs7VV1NCAIAtC8EIPiw2WyaeUlfzb6y5q66xev26+evpqu8ymNxZQAAtBwCEE5p6pgUPf2jcxVit+nt9COa/OcNyi3mKfIAgPaBAITTuvrcLvrL1PMU5Q7Rhv25unb+p/pvdpHVZQEA0GwEIJzR9/p20ht3jla3uDAdOF6ia+d/qk/25lhdFgAAzUIAwnfqkxClt+4coxE9YlVYVqUpizbob+v3c4cYAKDNIgChQTpGuvXybaN07dAu8lQbPfj2Dt332laVVTI4GgDQ9hCA0GChToeevGGIZl1+juw26fVNh3T9gnXKyC2xujQAABqFAIRGsdlsuv17vfTyraMUF+HSjiMFuvLZT7R6zzGrSwMAoMEIQGiS0WfF65/3nK8h3Toor6RSUxdt0O8/2KVKT7XVpQEA8J0IQGiy5A5hevV/UnXTqO4yRnru46806YX1XBIDAAQ8AhCaxR3i0O+uHaTnbhqmqNAQbTqYp8vnrdWKbZlWlwYAwGkRgNAiJgxO0op7x2po9w4qLKvSnX/fpAfe2KbSCu4SAwAEHgIQWky3uHC9+j9puvPC3rLZpCUbDmrCvLXadPCE1aUBAOCDAIQW5XTY9cvL+ulvPx2lxOhQfZ1TrIkL1umx93bxQFUAQMAgAKFVnN8nXh/M+J6uG9pF1UZ6fvVXuuqZT7X9cL7VpQEAQABC64kJd+rJSefqhcnDFR/p0u6jhbrmuU/15Mo99AYBACxFAEKru3RAoj6Y8T1dPihRVdVG8/61V5c/vVYb9uVaXRoAIEgRgOAXHSPdeu6mYXr2pqGKj3Trq2PFuuGF9Xrgja3KL6m0ujwAQJAhAMFvbDabrhicrH/NvEA3juwuSVqyIUMXP7lay7cc4enyAAC/IQDB72LCnZp73SC9Ni1NZ3WOVE5Rue5dslk3v/i59hwttLo8AEAQIADBMuf1jNO7956vmZf0lSvErk//e1zjn16rR97ZofxSLosBAFqPzXDdoZ6CggLFxMQoPz9f0dHRVpcTFDJyS/Tbd3fqgx1HJUlxES7976Vn64YR3eSw2yyuDgDQFjTm9zcB6BQIQNb5ZG+OZr+zQ//NLpIkDewSrYeuGKCRKXEWVwYACHQEoGYiAFmr0lOtv60/oD+u2qPCsipJ0g/O6axfXtZPfROiLK4OABCoCEDNRAAKDDlF5Xpy5R4t+yJDnmoju02aOLyrfn5JXyXFhFldHgAgwBCAmokAFFj+m12k33+wyzs+yB1i19QxPXXnBWcpJtxpcXUAgEBBAGomAlBg2njghB5770t9sb/m6fLRoSG69fxeuuX8nooOJQgBQLAjADUTAShwGWP0ry+z9fj7u7S3dqB0dGiIbhvbS1PHEIQAIJgRgJqJABT4PNVG727L1Lx/7fXeMRYT5tRt56do6pieiiIIAUDQIQA1EwGo7ThdEJqS1kNTRvdUx0i3xRUCAPyFANRMBKC251RBKNRp1w0juun2sb3ULS7c4goBAK2NANRMBKC2y1Nt9OGOLD2/+ittOZQvSXLYbZowKEn/c0EvDUiOsbhCAEBrIQA1EwGo7TPGaP1Xx7Vg9VdauzfHu37MWR01dXSKvt+vM4/YAIB2hgDUTASg9mX74Xy9sOZrvbv1iKpr/7Z3iwvTT1J76oYR3ZhLCADaCQJQMxGA2qdDJ0r0t88OaOmGDO/T5sOcDl03rIumju6pPjxmAwDaNAJQMxGA2rfSCo/eSj+sxZ/u1+6jhd71ab066sZR3XXpgAS5QxwWVggAaAoCUDMRgIKDMUaffZ2rxev2aeXOo97LY7HhTl03rKtuHNlNZ3WmVwgA2goCUDMRgILPoRMlevWLDL36n0PKKijzrh/RI1Y/GtldEwYlKcxFrxAABDICUDMRgIJXladaq/cc05INGfp4d7Y8td1CUe4QXT4oSdcO66KRPeNk5w4yAAg4BKBmIgBBko4WlOm1/2Ro2X8ylJFb6l3fpUOYrh3aRdcO66LenSItrBAAcDICUDMRgHCy6mqjDftz9eamw1qxLVOF5VXebUO6xujaoV10+eAkdY4KtbBKAAABqJkIQDidskqPVu48qjc3H9bqPce8l8hsNmlUSpwmDErSZQOT1CmKZ5ABgL8RgJqJAISGyCkq1ztbjujt9CNKz8jzrrfbpFEpHXX54CRdNiCRMAQAfkIAaiYCEBrr0IkSvbctS//clqktpwhDlw5I0A/6J6hrLA9lBYDWQgBqJgIQmiMjt0Tvbc/Uu1szvQ9krXNOUrQu6Z+gS85J0MAu0bLZuJsMAFoKAaiZCEBoKRm5JXp/e5ZWfnlU/9mf651sUZKSYkL1g3NqeoZSe8Ux+zQANBMBqJkIQGgNucUV+nhXtlbuPKo1e4+ppMLj3RbmdCitd0dd0LeTLujbST3jIyysFADaJgJQMxGA0NrKKj1a/9VxrfzyqP715VEdLSj32d49LtwbhtJ6d1SEO8SiSgGg7SAANRMBCP5kjNHuo4VavfuYVu85pi/256rS881/lk6HTSN6xOn8PvFK691Rg7vEKMRht7BiAAhMBKBmIgDBSsXlVVr/1XGt3lMTiA7mlvhsj3A5NDIlTmm9O2p073idkxQtB4/mAAACUHMRgBBI9ucUa/WeY1r/1XGt//q48ksrfbZHh4YotVdHpfXuqFEpHXV2YhSBCEBQIgA1EwEIgaq62mhnZoE++/q41n11XBv25aropEdzSDUPbh3aI1bn9YjViJ5xOrdbB55kDyAoEICaiQCEtqLKU61th/O17qvj+uzr49p04ISKT7q7TJJC7DYN6BLjDUQjesYqPpLZqQG0P20qAM2fP1+///3vlZmZqQEDBuipp57S2LFjT7v/6tWrNXPmTO3YsUPJycn65S9/qWnTpnm3L168WLfccku9z5WWlio0tGEPqyQAoa2q8lRrV1ah/rM/V18cOKH/7M+td4eZVHOX2ZBuHXRutw46t1uMBiTHKNRJLxGAtq0xv78tvbd22bJlmjFjhubPn68xY8bohRde0Pjx47Vz505179693v779u3T5Zdfrttvv10vv/yyPv30U915553q1KmTrr/+eu9+0dHR2r17t89nGxp+gLYsxGHXwC4xGtglRlPHpMgYo0MnSvWfA7n6Yn9NINpztEgHc0t0MLdE72w5Ikly2G3qlxhVE4q6dtCQbh10VudIxhIBaLcs7QEaNWqUhg0bpgULFnjXnXPOObrmmms0d+7cevv/6le/0vLly/Xll196102bNk1btmzR+vXrJdX0AM2YMUN5eXlNroseILRn+SWV2no4T1sy8pSeka/0jDzlFNXvJYpwObxhakBytAYkx6h3pwhuwQcQsNpED1BFRYU2btyo+++/32f9uHHjtG7dulN+Zv369Ro3bpzPuksvvVQvvviiKisr5XQ6JUlFRUXq0aOHPB6Pzj33XD366KMaOnToaWspLy9Xefk3vwAKCgqaelpAwIsJd2psn04a26eTpJp5iDLzy5SeUReK8rTtcL6KKzz6fF+uPt+X6/2sO8SufolR6p9cF4qi1S8xmkHWANocywJQTk6OPB6PEhISfNYnJCQoKyvrlJ/Jyso65f5VVVXKyclRUlKS+vXrp8WLF2vQoEEqKCjQ008/rTFjxmjLli3q06fPKY87d+5cPfLIIy1zYkAbY7PZlNwhTMkdwnT5oCRJkqfa6L/ZRdqSkacdR/K140iBvswsUHGFR1sO5fs85NVuk3p3itSA5Gj1T47W2YnROjshSgnRbh72CiBgWT6//rf/gTTGnPEfzVPtf/L61NRUpaamerePGTNGw4YN0zPPPKN58+ad8pgPPPCAZs6c6X1fUFCgbt26Ne5EgHbEYbfp7MQonZ0YJanmv4XqaqMDuSXeQLTjSIF2HslXTlGF9mYXaW92kd5KP+I9RnRoiM5OjFLfhCj1q/3ZNyFKsREui84KAL5hWQCKj4+Xw+Go19uTnZ1dr5enTmJi4in3DwkJUceOHU/5GbvdrvPOO0979+49bS1ut1tuN7cFA2dit9uUEh+hlPgIXTE4WVLN/4BkF5bXhKLDBfoyq0B7jhZpX06xCsqq9MX+E/pi/wmf43SOcnuD0dkJUTorIVK94yMVE+604rQABCnLApDL5dLw4cO1cuVKXXvttd71K1eu1NVXX33Kz6Slpemdd97xWffhhx9qxIgR3vE/32aMUXp6ugYNGtRyxQOQVNPzmhAdqoToUH2/3zf/41Je5dHXx4q1O6tQu48Wak/tz0MnSpVdWK7swnKt3Zvjc6z4SJd6dYpU704R6t0pUr1qf3aNDeduNAAtztJLYDNnztTkyZM1YsQIpaWlaeHChTp48KB3Xp8HHnhAhw8f1ksvvSSp5o6vZ599VjNnztTtt9+u9evX68UXX9SSJUu8x3zkkUeUmpqqPn36qKCgQPPmzVN6erqee+45S84RCEbuEIfOSYrWOUm+d2EUlVdp79FC7TlaqN1ZRdp9tEBfZRcrq6BMOUUVyinK1YaTBl1LksthV8/4cPWKj1TvzhHqFV8TjlLiI9QhnMtpAJrG0gA0adIkHT9+XHPmzFFmZqYGDhyoFStWqEePHpKkzMxMHTx40Lt/SkqKVqxYoZ///Od67rnnlJycrHnz5vnMAZSXl6c77rhDWVlZiomJ0dChQ7VmzRqNHDnS7+cHwFekO0RDu8dqaPdYn/VF5VXad6xYX+cU6avsIn2VU6yvsmsupZVXVWvP0SLtOVok7fA9XnRoiHp0jFCPjuE1S1zd6wh1jnLLTs8RgNOwfCboQMQ8QEBgqK42OpxXqq9rA1FNQKoJSqea4fpkoU67useFq3tchHrWBqTuHSPUPS5cyR1C5Q7h1n2gvWlTj8IIRAQgIPCVVniUcaJE+3OKdTC3RPuPF+vA8RIdOF6iw3ml8lSf+Z+2hGi3unQIU9fYcHWNDVOX2JNedwjj0SBAG9QmJkIEgOYIczm8t9Z/W6WnWkfySrX/eIkOHi/W/tpgdOB4sQ6dKFVppUdHC8p1tKBcmw7mnfL48ZHuk4JRbTjqEKbEmFAlx4QpOiyEeY6ANowABKDdcTrstWODIiR18tlmjFFucYUOnSjV4bxSHTpRUvP6RKkOnah5X1zhUU5RuXKKypWekXfK7whzOpQUE6rEmFAlxYSd9Pqb9x3CnYQkIEARgAAEFZvNpo6RbnWMdGtItw71thtjlF9a6Q1Dh7zBqCYwZeWX6kRJpUorPfo6p1hf5xSf9rtCnXYlxYQpMTrUJyB1jg5V5yi3OkeHqlOkW64Qnq8G+BsBCABOYrPZ1CHcpQ7hLg3sEnPKfcoqPcrKL1Nmfpky80uVmV9W+/6b18eLK1RWWa19OcXad4aQJEmx4U51jgpV52i3OkW5a15HudU52vd1uIt/soGWwn9NANBIoU6HesZHqGd8xGn3Kav06GhB2Unh6JuAlF1YrmMFZTpWVK5Kj9GJkkqdKKnU7qOFZ/zeSHeIOkfVhqTaXqT4SLc6RroUH+mqfe1WxwgXg7iB70AAAoBWEOp0nDQO6dSqq43ySiuVXVim7ILy2lmya14fq3tdWK7sgnKVVnpUVF6lovKqM152qxPpDlHHSJc6RrjUMbImKMWf9L5jXWCKcCk23MWcSQg6BCAAsIjdblNchEtxES71Szz9fsYYFZVXecNQdmFZbUAq1/GiCuUUlet4cc3r40UVqvBUe8PSgeMl312HTYqLqAlIcREuxUa4FBvuVFztpcDYCKdiw2uCUlyESx3CnYp0cxcc2jYCEAAEOJvNpqhQp6JCnerdKfKM+xpjVFheVRuGypVTVKHjxeXKKazwhqSawFSz/URJpaqNvHe9NZTTUTNWKjb8m3DkDU4RNcEpLsJZu49LceEuRYWG0NOEgEEAAoB2xGazKTrUqehQp1LOMEapTqWnWidKKrwBKbe4QieKK5RbUqm8kgrlFlcor6Sy9meFcktqBndXeoyOFdZcqmt4bVJ0qFMxYd9awk+x7lvbI12EJ7QsAhAABDGnw157p1logz9TWuHRiZKKmqW48tSvSyp1orhufYWKKzwyRsovrVR+aWWj67TbpOgzhaTaJSrUqcjQEEWFhig6NKS25yxEYU4Hl+zggwAEAGiUMJdDYa4wJXcIa/Bnyqs8yi+tVEFtAMovrVReyTev65aCU2wrr6pWtZHySmrWN0WI3eYNRlHumlAUFeqsDUnfBKVvfp68vWZduIsQ1Z4QgAAArc4d4lDnKEejeprqlFV6fILTqcJTQWmlCsoqVVBWpcKyKhWW1awrKq9StZGqqs1JAaq0SefgsNsU6f4mHEW6HYpwhyjCHaJIV+3P2nWRoSGKdIcowrs+RBFuR+1PwlQgIAABAAJaqNOhUKdDnaMbH56MMSqu8KiwrPKbYHRSSPL9efrt1UbyVJuTLuE1LUTVsdlUG45qAlNUbTA6OSz5Bqu67TUhKszlUISrJkiFuRwKd4XIwRipRiEAAQDaLZutptcm0h2ipFNP7P2djDEqqfD4BKSi8ioVl3/zs+a1x7vOd32Viuu2VVTJGMkYefeTGj6Q/EzcIXaF14ahmp8Ob1AKq33vuy1EEScFqJNfh5+0f6jT3i57qwhAAACcgc1m8/bOJMY0vhfqZMYY76SWxScFpnpBqS5AVdT0RhXXbisqr1JJRZVKKjwqrfCouKLmEp8klVdVq7yqWieaOE7qdGw2KdxZE5i+CUY1YSnMGVL7066w2n1qftZ/H+p0KMxZE6rCnA5FhoYoLsLVorU2BgEIAAA/sdlstT0sIVJU849njFF5VbU3DJVWeFTyrdd1genk1zX7e1Ra+/7k13X7lVVW136HVFy7T0sa3DVGy+8+v0WP2RgEIAAA2iibzeYdIxXbwr0pnuqa3qqS2jBVXO5RaWVtYCr3qKzSo9LKmjDl87PSo7La1yW1P8tqt5dUfPO5CIsf7ksAAgAA9dTd9Rbpbp2oYIxpleM2lN3SbwcAAEHJ6oHVBCAAABB0CEAAACDoEIAAAEDQIQABAICgQwACAABBhwAEAACCDgEIAAAEHQIQAAAIOgQgAAAQdAhAAAAg6BCAAABA0CEAAQCAoEMAAgAAQad1nnHfxhljJEkFBQUWVwIAABqq7vd23e/xMyEAnUJhYaEkqVu3bhZXAgAAGquwsFAxMTFn3MdmGhKTgkx1dbWOHDmiqKgo2Wy2Fj12QUGBunXrpoyMDEVHR7fosfEN2tl/aGv/oJ39g3b2n9Zoa2OMCgsLlZycLLv9zKN86AE6Bbvdrq5du7bqd0RHR/Mflx/Qzv5DW/sH7ewftLP/tHRbf1fPTx0GQQMAgKBDAAIAAEGHAORnbrdbDz/8sNxut9WltGu0s//Q1v5BO/sH7ew/Vrc1g6ABAEDQoQcIAAAEHQIQAAAIOgQgAAAQdAhAAAAg6BCA/Gj+/PlKSUlRaGiohg8frrVr11pdUpuyZs0aXXnllUpOTpbNZtNbb73ls90Yo9mzZys5OVlhYWG68MILtWPHDp99ysvLdc899yg+Pl4RERG66qqrdOjQIT+eReCbO3euzjvvPEVFRalz58665pprtHv3bp99aOuWsWDBAg0ePNg7EVxaWpree+8973bauXXMnTtXNptNM2bM8K6jrZtv9uzZstlsPktiYqJ3e8C1sYFfLF261DidTvOnP/3J7Ny500yfPt1ERESYAwcOWF1am7FixQoza9Ys8/rrrxtJ5s033/TZ/thjj5moqCjz+uuvm23btplJkyaZpKQkU1BQ4N1n2rRppkuXLmblypVm06ZN5qKLLjJDhgwxVVVVfj6bwHXppZeaRYsWme3bt5v09HQzYcIE0717d1NUVOTdh7ZuGcuXLzfvvvuu2b17t9m9e7f59a9/bZxOp9m+fbsxhnZuDRs2bDA9e/Y0gwcPNtOnT/eup62b7+GHHzYDBgwwmZmZ3iU7O9u7PdDamADkJyNHjjTTpk3zWdevXz9z//33W1RR2/btAFRdXW0SExPNY4895l1XVlZmYmJizPPPP2+MMSYvL884nU6zdOlS7z6HDx82drvdvP/++36rva3Jzs42kszq1auNMbR1a4uNjTV//vOfaedWUFhYaPr06WNWrlxpLrjgAm8Aoq1bxsMPP2yGDBlyym2B2MZcAvODiooKbdy4UePGjfNZP27cOK1bt86iqtqXffv2KSsry6eN3W63LrjgAm8bb9y4UZWVlT77JCcna+DAgfw5nEF+fr4kKS4uThJt3Vo8Ho+WLl2q4uJipaWl0c6t4K677tKECRP0gx/8wGc9bd1y9u7dq+TkZKWkpOhHP/qRvv76a0mB2cY8DNUPcnJy5PF4lJCQ4LM+ISFBWVlZFlXVvtS146na+MCBA959XC6XYmNj6+3Dn8OpGWM0c+ZMnX/++Ro4cKAk2rqlbdu2TWlpaSorK1NkZKTefPNN9e/f3/sPPu3cMpYuXapNmzbpiy++qLeNv9MtY9SoUXrppZfUt29fHT16VL/97W81evRo7dixIyDbmADkRzabzee9MabeOjRPU9qYP4fTu/vuu7V161Z98skn9bbR1i3j7LPPVnp6uvLy8vT6669rypQpWr16tXc77dx8GRkZmj59uj788EOFhoaedj/aunnGjx/vfT1o0CClpaWpd+/e+utf/6rU1FRJgdXGXALzg/j4eDkcjnoJNjs7u14aRtPU3WlwpjZOTExURUWFTpw4cdp98I177rlHy5cv18cff6yuXbt619PWLcvlcumss87SiBEjNHfuXA0ZMkRPP/007dyCNm7cqOzsbA0fPlwhISEKCQnR6tWrNW/ePIWEhHjbirZuWRERERo0aJD27t0bkH+fCUB+4HK5NHz4cK1cudJn/cqVKzV69GiLqmpfUlJSlJiY6NPGFRUVWr16tbeNhw8fLqfT6bNPZmamtm/fzp/DSYwxuvvuu/XGG2/oo48+UkpKis922rp1GWNUXl5OO7egiy++WNu2bVN6erp3GTFihH784x8rPT1dvXr1oq1bQXl5ub788kslJSUF5t/nFh9WjVOquw3+xRdfNDt37jQzZswwERERZv/+/VaX1mYUFhaazZs3m82bNxtJ5sknnzSbN2/2TiXw2GOPmZiYGPPGG2+Ybdu2mRtvvPGUt1h27drVrFq1ymzatMl8//vf5zbWb/nZz35mYmJizL///W+f21lLSkq8+9DWLeOBBx4wa9asMfv27TNbt241v/71r43dbjcffvihMYZ2bk0n3wVmDG3dEn7xi1+Yf//73+brr782n332mbniiitMVFSU9/dcoLUxAciPnnvuOdOjRw/jcrnMsGHDvLcVo2E+/vhjI6neMmXKFGNMzW2WDz/8sElMTDRut9t873vfM9u2bfM5Rmlpqbn77rtNXFycCQsLM1dccYU5ePCgBWcTuE7VxpLMokWLvPvQ1i3jpz/9qfffhE6dOpmLL77YG36MoZ1b07cDEG3dfHXz+jidTpOcnGyuu+46s2PHDu/2QGtjmzHGtHy/EgAAQOBiDBAAAAg6BCAAABB0CEAAACDoEIAAAEDQIQABAICgQwACAABBhwAEAACCDgEIABrAZrPprbfesroMAC2EAAQg4E2dOlU2m63ectlll1ldGoA2KsTqAgCgIS677DItWrTIZ53b7baoGgBtHT1AANoEt9utxMREnyU2NlZSzeWpBQsWaPz48QoLC1NKSopee+01n89v27ZN3//+9xUWFqaOHTvqjjvuUFFRkc8+f/nLXzRgwAC53W4lJSXp7rvv9tmek5Oja6+9VuHh4erTp4+WL1/euicNoNUQgAC0Cw8++KCuv/56bdmyRTfffLNuvPFGffnll5KkkpISXXbZZYqNjdUXX3yh1157TatWrfIJOAsWLNBdd92lO+64Q9u2bdPy5ct11lln+XzHI488ohtuuEFbt27V5Zdfrh//+MfKzc3163kCaCGt8ohVAGhBU6ZMMQ6Hw0RERPgsc+bMMcbUPMF+2rRpPp8ZNWqU+dnPfmaMMWbhwoUmNjbWFBUVebe/++67xm63m6ysLGOMMcnJyWbWrFmnrUGS+c1vfuN9X1RUZGw2m3nvvfda7DwB+A9jgAC0CRdddJEWLFjgsy4uLs77Oi0tzWdbWlqa0tPTJUlffvmlhgwZooiICO/2MWPGqLq6Wrt375bNZtORI0d08cUXn7GGwYMHe19HREQoKipK2dnZTT0lABYiAAFoEyIiIupdkvouNptNkmSM8b4+1T5hYWENOp7T6az32erq6kbVBCAwMAYIQLvw2Wef1Xvfr18/SVL//v2Vnp6u4uJi7/ZPP/1Udrtdffv2VVRUlHr27Kl//etffq0ZgHXoAQLQJpSXlysrK8tnXUhIiOLj4yVJr732mkaMGKHzzz9ff//737Vhwwa9+OKLkqQf//jHevjhhzVlyhTNnj1bx44d0z333KPJkycrISFBkjR79mxNmzZNnTt31vjx41VYWKhPP/1U99xzj39PFIBfEIAAtAnvv/++kpKSfNadffbZ2rVrl6SaO7SWLl2qO++8U4mJifr73/+u/v37S5LCw8P1wQcfaPr06TrvvPMUHh6u66+/Xk8++aT3WFOmTFFZWZn++Mc/6r777lN8fLwmTpzovxME4Fc2Y4yxuggAaA6bzaY333xT11xzjdWlAGgjGAMEAACCDgEIAAAEHcYAAWjzuJIPoLHoAQIAAEGHAAQAAIIOAQgAAAQdAhAAAAg6BCAAABB0CEAAACDoEIAAAEDQIQABAICgQwACAABB5/8DvtG+SgxMeuAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7ae2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af46db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
